{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061ebf49-eb9a-4bf7-9abd-df48abd808a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 19 16:31:26 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P8              10W /  70W |      5MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cbe14-22e7-4d4c-b835-c176e543f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041155b-48e7-46e7-a068-0862e18a8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfc73f-5861-4f40-a8f9-e753b0c2c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b239503b-da6d-46a9-8b05-6c652cb7ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/llm/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d97ec7-b543-42ad-bb23-b2ed1f37a705",
   "metadata": {},
   "source": [
    "https://data.world/collery/post-office-data/workspace/file?filename=USPO+Change+of+Address+data+Y2022.csv\n",
    "https://data.world/len/us-first-names-database\n",
    "\n",
    "https://www.kaggle.com/datasets/ahmedshahriarsakib/list-of-real-usa-addresses\n",
    "https://www.kaggle.com/datasets/datagov/usa-names\n",
    "\n",
    "https://data.world/adamhelsinger/directory-of-representatives\n",
    "https://data.world/state-of-connecticut/ikyf-f2iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78129f7c-1798-4c14-a829-2fa6534c2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69803fa1-cf40-448c-aa05-3386ae881cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1098025-6ab9-492f-991e-4e4ffc487e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b7e109-2d42-477f-84f7-b519236b0419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2376206.0</td>\n",
       "      <td>880.85</td>\n",
       "      <td>880.85</td>\n",
       "      <td>73.35</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1857160.0</td>\n",
       "      <td>688.44</td>\n",
       "      <td>1569.30</td>\n",
       "      <td>61.55</td>\n",
       "      <td>33.80</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1534042.0</td>\n",
       "      <td>568.66</td>\n",
       "      <td>2137.96</td>\n",
       "      <td>48.52</td>\n",
       "      <td>46.72</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROWN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1380145.0</td>\n",
       "      <td>511.62</td>\n",
       "      <td>2649.58</td>\n",
       "      <td>60.71</td>\n",
       "      <td>34.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JONES</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1362755.0</td>\n",
       "      <td>505.17</td>\n",
       "      <td>3154.75</td>\n",
       "      <td>57.69</td>\n",
       "      <td>37.73</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  rank      count  prop100k  cum_prop100k pctwhite pctblack pctapi  \\\n",
       "0     SMITH   1.0  2376206.0    880.85        880.85    73.35    22.22   0.40   \n",
       "1   JOHNSON   2.0  1857160.0    688.44       1569.30    61.55    33.80   0.42   \n",
       "2  WILLIAMS   3.0  1534042.0    568.66       2137.96    48.52    46.72   0.37   \n",
       "3     BROWN   4.0  1380145.0    511.62       2649.58    60.71    34.54   0.41   \n",
       "4     JONES   5.0  1362755.0    505.17       3154.75    57.69    37.73   0.35   \n",
       "\n",
       "  pctaian pct2prace pcthispanic  \n",
       "0    0.85      1.63        1.56  \n",
       "1    0.91      1.82        1.50  \n",
       "2    0.78      2.01        1.60  \n",
       "3    0.83      1.86        1.64  \n",
       "4    0.94      1.85        1.44  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "surnames = pd.read_csv(\"data/Common_Surnames_Census_2000.csv\")\n",
    "\n",
    "# View the first 5 rows\n",
    "surnames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da9f4ac-4f2e-4c55-b15f-6a90eac3abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames = surnames.drop(['rank', 'count', 'prop100k', 'cum_prop100k', 'pctwhite', 'pctblack', 'pctapi', 'pctaian', 'pct2prace', 'pcthispanic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd44dd2-8dfb-4ff7-9b3f-66f9b5e94b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85502, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886a2a0a-275a-4e30-8ac7-33fc00749e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JONES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name\n",
       "0     SMITH\n",
       "1   JOHNSON\n",
       "2  WILLIAMS\n",
       "3     BROWN\n",
       "4     JONES"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a5f35c-da9c-4f4f-ac78-720e22de5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames = surnames.drop_duplicates(subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc17ea01-55b1-4691-b190-18624d37a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames = surnames.rename(columns={\"name\": \"lastname\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d33256-5efc-432b-a1ce-0aabb1ddeb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Include?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emma</td>\n",
       "      <td>F</td>\n",
       "      <td>20355</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia</td>\n",
       "      <td>F</td>\n",
       "      <td>19553</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noah</td>\n",
       "      <td>M</td>\n",
       "      <td>19511</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liam</td>\n",
       "      <td>M</td>\n",
       "      <td>18281</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophia</td>\n",
       "      <td>F</td>\n",
       "      <td>17327</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Gender  Frequency Include?\n",
       "0    Emma      F      20355      Yes\n",
       "1  Olivia      F      19553      Yes\n",
       "2    Noah      M      19511      Yes\n",
       "3    Liam      M      18281      Yes\n",
       "4  Sophia      F      17327      Yes"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "firstnameandgender = pd.read_csv(\"data/SSA_Names_DB.csv\")\n",
    "\n",
    "# View the first 5 rows\n",
    "firstnameandgender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8159bfb5-cc9d-42f4-85b0-ac99273cf712",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnameandgender = firstnameandgender.drop(['Frequency', 'Include?',], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acaf5a14-2548-4069-a815-d1549314a26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32952, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnameandgender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcd5a5ce-199e-4f9a-9c7f-ec9e83fa4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnameandgender = firstnameandgender.drop_duplicates(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49e785ce-3e8d-414d-a2e2-f37f765c9abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30460, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnameandgender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb5a0883-02cd-4871-96eb-032f6ceb937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnameandgender = firstnameandgender.rename(columns={\"Name\": \"firstname\", \"Gender\": \"gender\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5ebe9b8-9d14-4b56-931c-7979c31c326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30460, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnameandgender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e77a510-3d63-4a2b-bd61-5e52aa22137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emma</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noah</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liam</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophia</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  firstname gender\n",
       "0      Emma      F\n",
       "1    Olivia      F\n",
       "2      Noah      M\n",
       "3      Liam      M\n",
       "4    Sophia      F"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnameandgender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa0b115b-8afe-4b03-b933-13f4306aac25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYYYMM</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>TOTAL FROM ZIP</th>\n",
       "      <th>TOTAL BUSINESS</th>\n",
       "      <th>TOTAL FAMILY</th>\n",
       "      <th>TOTAL INDIVIDUAL</th>\n",
       "      <th>TOTAL PERM</th>\n",
       "      <th>TOTAL TEMP</th>\n",
       "      <th>TOTAL TO ZIP</th>\n",
       "      <th>TOTAL BUSINESS.1</th>\n",
       "      <th>TOTAL FAMILY.1</th>\n",
       "      <th>TOTAL INDIVIDUAL.1</th>\n",
       "      <th>TOTAL PERM.1</th>\n",
       "      <th>TOTAL TEMP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202201</td>\n",
       "      <td>=\"00601\"</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>PR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202201</td>\n",
       "      <td>=\"00602\"</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>PR</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202201</td>\n",
       "      <td>=\"00603\"</td>\n",
       "      <td>AGUADILLA</td>\n",
       "      <td>PR</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202201</td>\n",
       "      <td>=\"00605\"</td>\n",
       "      <td>AGUADILLA</td>\n",
       "      <td>PR</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202201</td>\n",
       "      <td>=\"00610\"</td>\n",
       "      <td>ANASCO</td>\n",
       "      <td>PR</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YYYYMM   ZIPCODE                          CITY STATE  TOTAL FROM ZIP  \\\n",
       "0  202201  =\"00601\"  ADJUNTAS                        PR               0   \n",
       "1  202201  =\"00602\"  AGUADA                          PR              18   \n",
       "2  202201  =\"00603\"  AGUADILLA                       PR              31   \n",
       "3  202201  =\"00605\"  AGUADILLA                       PR              13   \n",
       "4  202201  =\"00610\"  ANASCO                          PR              11   \n",
       "\n",
       "   TOTAL BUSINESS  TOTAL FAMILY  TOTAL INDIVIDUAL  TOTAL PERM  TOTAL TEMP  \\\n",
       "0               0             0                 0           0           0   \n",
       "1               0             0                14          17           0   \n",
       "2               0             0                24          24           0   \n",
       "3               0             0                12          12           0   \n",
       "4               0             0                 0           0           0   \n",
       "\n",
       "   TOTAL TO ZIP  TOTAL BUSINESS.1  TOTAL FAMILY.1  TOTAL INDIVIDUAL.1  \\\n",
       "0            13                 0               0                  11   \n",
       "1            43                 0               0                  39   \n",
       "2            65                 0              11                  51   \n",
       "3            11                 0               0                   0   \n",
       "4            17                 0               0                   0   \n",
       "\n",
       "   TOTAL PERM.1  TOTAL TEMP.1  \n",
       "0            12             0  \n",
       "1            30            13  \n",
       "2            40            25  \n",
       "3            11             0  \n",
       "4             0             0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "address = pd.read_csv(\"data/USPO Change of Address data Y2022.csv\")\n",
    "\n",
    "# View the first 5 rows\n",
    "address.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ead6e3d3-859c-4223-b7b5-705c43f71c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = address.drop(['YYYYMM', 'TOTAL FROM ZIP',\"TOTAL BUSINESS\", \"TOTAL FAMILY\", \"TOTAL INDIVIDUAL\", \"TOTAL PERM\", \"TOTAL TEMP\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb92f184-a6f6-4f7f-a4fa-0f3861f293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = address.drop(['TOTAL TO ZIP', 'TOTAL BUSINESS.1',\"TOTAL FAMILY.1\", \"TOTAL INDIVIDUAL.1\", \"TOTAL PERM.1\", \"TOTAL TEMP.1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef7942ad-e5e4-4b05-b925-5d4078ac0a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=\"00601\"</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>=\"00602\"</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>=\"00603\"</td>\n",
       "      <td>AGUADILLA</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>=\"00605\"</td>\n",
       "      <td>AGUADILLA</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>=\"00610\"</td>\n",
       "      <td>ANASCO</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ZIPCODE                          CITY STATE\n",
       "0  =\"00601\"  ADJUNTAS                        PR\n",
       "1  =\"00602\"  AGUADA                          PR\n",
       "2  =\"00603\"  AGUADILLA                       PR\n",
       "3  =\"00605\"  AGUADILLA                       PR\n",
       "4  =\"00610\"  ANASCO                          PR"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bca2002-5fb2-468c-b87e-2173d819a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "address['ZIPCODE'] = address['ZIPCODE'].apply(lambda x: x.replace('=', '').replace('\"', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bfbe2fb-bd7e-42bb-b055-4889581aa515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00601</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00602</td>\n",
       "      <td>AGUADA</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00603</td>\n",
       "      <td>AGUADILLA</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00605</td>\n",
       "      <td>AGUADILLA</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00610</td>\n",
       "      <td>ANASCO</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ZIPCODE                          CITY STATE\n",
       "0   00601  ADJUNTAS                        PR\n",
       "1   00602  AGUADA                          PR\n",
       "2   00603  AGUADILLA                       PR\n",
       "3   00605  AGUADILLA                       PR\n",
       "4   00610  ANASCO                          PR"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c996639-3049-4e52-931a-c4e0838e538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = address.rename(columns={\"ZIPCODE\": \"zipcode\", \"CITY\": \"city\", \"STATE\": \"state\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3167f30b-d9df-4c63-be4a-fd60321b6d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278400, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cda1b374-9dae-4794-a4d5-5f4a496be922",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=address.city.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c58b78b9-f1a3-4ade-bcd6-d1729c7f3724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14806"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91e87bb7-9714-4baa-b02f-8fb93bceb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "address = address.sample(frac = 1)\n",
    "firstnameandgender = firstnameandgender.sample(frac = 1)\n",
    "surnames = surnames.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c98fd2a-c4c0-4675-b1f0-8d9d13ec4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "address.reset_index(inplace = True,  drop=True)\n",
    "firstnameandgender.reset_index(inplace = True,  drop=True)\n",
    "surnames.reset_index(inplace = True,  drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "299dbf96-b78b-48b2-8ba1-a079e4af840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames=surnames.iloc[:30460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f48e0b7f-5fd3-4e25-a044-02e9e5591c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnameandgender=firstnameandgender.iloc[:30460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "952d6951-e282-4b9c-9c05-9b7f07d7c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "address=address.iloc[:30460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68337159-c67d-4502-ace3-75bdaa5f3421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30460, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a77ac7bf-eb81-46ac-a335-0aff06b2e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat = pd.concat([firstnameandgender, surnames, address], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36480ccd-ead8-4b8a-84de-c254996b4559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastname</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lanya</td>\n",
       "      <td>F</td>\n",
       "      <td>HAMMA</td>\n",
       "      <td>35640</td>\n",
       "      <td>HARTSELLE</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellanora</td>\n",
       "      <td>F</td>\n",
       "      <td>PATTENGALE</td>\n",
       "      <td>07417</td>\n",
       "      <td>FRANKLIN LAKES</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riya</td>\n",
       "      <td>F</td>\n",
       "      <td>TOBIASZ</td>\n",
       "      <td>33621</td>\n",
       "      <td>TAMPA</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Briza</td>\n",
       "      <td>F</td>\n",
       "      <td>LAGACE</td>\n",
       "      <td>30070</td>\n",
       "      <td>PORTERDALE</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prosperity</td>\n",
       "      <td>F</td>\n",
       "      <td>PAPENDICK</td>\n",
       "      <td>12053</td>\n",
       "      <td>DELANSON</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    firstname gender    lastname zipcode                          city state\n",
       "0       Lanya      F       HAMMA   35640  HARTSELLE                       AL\n",
       "1    Ellanora      F  PATTENGALE   07417  FRANKLIN LAKES                  NJ\n",
       "2        Riya      F     TOBIASZ   33621  TAMPA                           FL\n",
       "3       Briza      F      LAGACE   30070  PORTERDALE                      GA\n",
       "4  Prosperity      F   PAPENDICK   12053  DELANSON                        NY"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fe15b34-1772-47df-9162-16ec2754aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat.reset_index(inplace=True, drop=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9055e3a3-dbee-4179-84a3-113e0d81f85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30460, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c168906d-c8c8-41bb-b706-8453561d2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat['firstname'] = horizontal_concat['firstname'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a0d95a7-dada-4d6e-8fc0-778d3d2bc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat['gender'] = horizontal_concat['gender'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e496e8c-b725-4c08-bdec-790ea872548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat['lastname'] = horizontal_concat['lastname'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "015a1a7c-4e1e-42e9-8c3a-0a55cf52596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat['city'] = horizontal_concat['city'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a79fcd7-8373-4b6d-9952-f0cf6c1beeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_concat['state'] = horizontal_concat['state'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "841b4df5-00e0-4232-bf47-2c67c1b9406f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastname</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lanya</td>\n",
       "      <td>f</td>\n",
       "      <td>hamma</td>\n",
       "      <td>35640</td>\n",
       "      <td>hartselle</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ellanora</td>\n",
       "      <td>f</td>\n",
       "      <td>pattengale</td>\n",
       "      <td>07417</td>\n",
       "      <td>franklin lakes</td>\n",
       "      <td>nj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>riya</td>\n",
       "      <td>f</td>\n",
       "      <td>tobiasz</td>\n",
       "      <td>33621</td>\n",
       "      <td>tampa</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>briza</td>\n",
       "      <td>f</td>\n",
       "      <td>lagace</td>\n",
       "      <td>30070</td>\n",
       "      <td>porterdale</td>\n",
       "      <td>ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prosperity</td>\n",
       "      <td>f</td>\n",
       "      <td>papendick</td>\n",
       "      <td>12053</td>\n",
       "      <td>delanson</td>\n",
       "      <td>ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30455</th>\n",
       "      <td>arizona</td>\n",
       "      <td>f</td>\n",
       "      <td>miu</td>\n",
       "      <td>25921</td>\n",
       "      <td>sophia</td>\n",
       "      <td>wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30456</th>\n",
       "      <td>mayci</td>\n",
       "      <td>f</td>\n",
       "      <td>fausey</td>\n",
       "      <td>57754</td>\n",
       "      <td>lead</td>\n",
       "      <td>sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30457</th>\n",
       "      <td>yuto</td>\n",
       "      <td>m</td>\n",
       "      <td>zemke</td>\n",
       "      <td>12816</td>\n",
       "      <td>cambridge</td>\n",
       "      <td>ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30458</th>\n",
       "      <td>jentzen</td>\n",
       "      <td>m</td>\n",
       "      <td>dorosh</td>\n",
       "      <td>80932</td>\n",
       "      <td>colorado springs</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30459</th>\n",
       "      <td>esau</td>\n",
       "      <td>m</td>\n",
       "      <td>foucher</td>\n",
       "      <td>33677</td>\n",
       "      <td>tampa</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30460 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        firstname gender    lastname zipcode                          city  \\\n",
       "0           lanya      f       hamma   35640  hartselle                      \n",
       "1        ellanora      f  pattengale   07417  franklin lakes                 \n",
       "2            riya      f     tobiasz   33621  tampa                          \n",
       "3           briza      f      lagace   30070  porterdale                     \n",
       "4      prosperity      f   papendick   12053  delanson                       \n",
       "...           ...    ...         ...     ...                           ...   \n",
       "30455     arizona      f         miu   25921  sophia                         \n",
       "30456       mayci      f      fausey   57754  lead                           \n",
       "30457        yuto      m       zemke   12816  cambridge                      \n",
       "30458     jentzen      m      dorosh   80932  colorado springs               \n",
       "30459        esau      m     foucher   33677  tampa                          \n",
       "\n",
       "      state  \n",
       "0        al  \n",
       "1        nj  \n",
       "2        fl  \n",
       "3        ga  \n",
       "4        ny  \n",
       "...     ...  \n",
       "30455    wv  \n",
       "30456    sd  \n",
       "30457    ny  \n",
       "30458    co  \n",
       "30459    fl  \n",
       "\n",
       "[30460 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "924698c9-f788-4c7a-a2d8-c829d059131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Entity       Value\n",
      "0       firstname       lanya\n",
      "1       firstname    ellanora\n",
      "2       firstname        riya\n",
      "3       firstname       briza\n",
      "4       firstname  prosperity\n",
      "...           ...         ...\n",
      "182755      state          wv\n",
      "182756      state          sd\n",
      "182757      state          ny\n",
      "182758      state          co\n",
      "182759      state          fl\n",
      "\n",
      "[182760 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "# Melt the DataFrame to convert columns to rows\n",
    "melted_data = pd.melt(horizontal_concat, var_name='Entity', value_name='Value')\n",
    " \n",
    "# 'Entity' column now contains the labels for the entities (former column names)\n",
    "# 'Value' column contains the corresponding values\n",
    " \n",
    "print(melted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0d2981c-a8da-4c93-9622-094cc0b5d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['firstname', 'gender', 'lastname', 'zipcode', 'city', 'state'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_data['Entity'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c5274e8-10f9-4c74-92af-88824246262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels for each column\n",
    "labels = ['firstname', 'gender', 'lastname', 'zipcode', 'city', 'state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e438d0cb-55cd-411c-af02-91bb7f9e1827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: firstname\n",
      "Training set size: 21322\n",
      "Testing set size: 4569\n",
      "Validation set size: 4569\n",
      "===================\n",
      "Entity: gender\n",
      "Training set size: 21322\n",
      "Testing set size: 4569\n",
      "Validation set size: 4569\n",
      "===================\n",
      "Entity: lastname\n",
      "Training set size: 21322\n",
      "Testing set size: 4569\n",
      "Validation set size: 4569\n",
      "===================\n",
      "Entity: zipcode\n",
      "Training set size: 21322\n",
      "Testing set size: 4569\n",
      "Validation set size: 4569\n",
      "===================\n",
      "Entity: city\n",
      "Training set size: 21322\n",
      "Testing set size: 4569\n",
      "Validation set size: 4569\n",
      "===================\n",
      "Entity: state\n",
      "Training set size: 21322\n",
      "Testing set size: 4569\n",
      "Validation set size: 4569\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your melted data is stored in a DataFrame called 'melted_data'\n",
    "# and the labels are in a column named 'Value'\n",
    "\n",
    "entity_lists = melted_data['Entity'].unique()\n",
    "X_test_final = pd.DataFrame()\n",
    "X_train_final = pd.DataFrame()\n",
    "X_val_final = pd.DataFrame()\n",
    "y_train_final = pd.Series()\n",
    "y_test_final = pd.Series()\n",
    "y_val_final = pd.Series()\n",
    "\n",
    "for entity in entity_lists:\n",
    "    # Filter data for the current entity\n",
    "    entity_data = melted_data[melted_data['Entity'] == entity]\n",
    "    \n",
    "    # Split into features and labels\n",
    "   # X = entity_data.drop('Value', axis=1)  # Assuming 'Value' is the label column\n",
    "    X = entity_data['Value']\n",
    "    y = entity_data['Entity']\n",
    "    \n",
    "    # Split into train, test, and validation sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Append the splits to the final DataFrames and Series\n",
    "    X_train_final = pd.concat([X_train_final, X_train], ignore_index=True)\n",
    "    X_test_final = pd.concat([X_test_final, X_test], ignore_index=True)\n",
    "    X_val_final = pd.concat([X_val_final, X_val], ignore_index=True)\n",
    "    \n",
    "    y_train_final = pd.concat([y_train_final, y_train], ignore_index=True)\n",
    "    y_test_final = pd.concat([y_test_final, y_test], ignore_index=True)\n",
    "    y_val_final = pd.concat([y_val_final, y_val], ignore_index=True)\n",
    "\n",
    "    # Display the sizes of the splits for the current entity\n",
    "    print(f\"Entity: {entity}\")\n",
    "    print(\"Training set size:\", len(X_train))\n",
    "    print(\"Testing set size:\", len(X_test))\n",
    "    print(\"Validation set size:\", len(X_val))\n",
    "    print(\"===================\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21037adc-6c6c-42f2-82f5-9c9cee2e314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_final               0\n",
      "0       quintez\n",
      "1           jed\n",
      "2         noora\n",
      "3         adara\n",
      "4      shreshta\n",
      "...         ...\n",
      "27409        ky\n",
      "27410        mi\n",
      "27411        mi\n",
      "27412        tx\n",
      "27413        fl\n",
      "\n",
      "[27414 rows x 1 columns]\n",
      "X_train_final              0\n",
      "0       sharvi\n",
      "1       kaicen\n",
      "2       taryah\n",
      "3        mayte\n",
      "4        ivaan\n",
      "...        ...\n",
      "127927      nm\n",
      "127928      pa\n",
      "127929      wi\n",
      "127930      tx\n",
      "127931      tn\n",
      "\n",
      "[127932 rows x 1 columns]\n",
      "X_val_final              0\n",
      "0         adda\n",
      "1       fallou\n",
      "2        blimy\n",
      "3      bostynn\n",
      "4       brysyn\n",
      "...        ...\n",
      "27409       va\n",
      "27410       oh\n",
      "27411       wi\n",
      "27412       va\n",
      "27413       ks\n",
      "\n",
      "[27414 rows x 1 columns]\n",
      "y_train_final 0         firstname\n",
      "1         firstname\n",
      "2         firstname\n",
      "3         firstname\n",
      "4         firstname\n",
      "            ...    \n",
      "127927        state\n",
      "127928        state\n",
      "127929        state\n",
      "127930        state\n",
      "127931        state\n",
      "Length: 127932, dtype: object\n",
      "y_test_final 0        firstname\n",
      "1        firstname\n",
      "2        firstname\n",
      "3        firstname\n",
      "4        firstname\n",
      "           ...    \n",
      "27409        state\n",
      "27410        state\n",
      "27411        state\n",
      "27412        state\n",
      "27413        state\n",
      "Length: 27414, dtype: object\n",
      "y_val_final 0        firstname\n",
      "1        firstname\n",
      "2        firstname\n",
      "3        firstname\n",
      "4        firstname\n",
      "           ...    \n",
      "27409        state\n",
      "27410        state\n",
      "27411        state\n",
      "27412        state\n",
      "27413        state\n",
      "Length: 27414, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test_final\", X_test_final)\n",
    "print(\"X_train_final\", X_train_final)\n",
    "print(\"X_val_final\", X_val_final)\n",
    "print(\"y_train_final\", y_train_final)\n",
    "print(\"y_test_final\", y_test_final)\n",
    "print(\"y_val_final\", y_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd626900-1875-4dbd-9507-bf237b093631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_final 27414\n",
      "X_train_final 127932\n",
      "X_val_final 27414\n",
      "y_train_final 127932\n",
      "y_test_final 27414\n",
      "y_val_final 27414\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test_final\", len(X_test_final))\n",
    "print(\"X_train_final\", len(X_train_final))\n",
    "print(\"X_val_final\", len(X_val_final))\n",
    "print(\"y_train_final\", len(y_train_final))\n",
    "print(\"y_test_final\", len(y_test_final))\n",
    "print(\"y_val_final\", len(y_val_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52634b13-1460-4587-9e02-d5377f9028b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_data = melted_data[melted_data['Entity'] == 'firstname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d413ba4-d24d-4660-8e80-57e4bec7fc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firstname</td>\n",
       "      <td>lanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firstname</td>\n",
       "      <td>ellanora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firstname</td>\n",
       "      <td>riya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firstname</td>\n",
       "      <td>briza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>firstname</td>\n",
       "      <td>prosperity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entity       Value\n",
       "0  firstname       lanya\n",
       "1  firstname    ellanora\n",
       "2  firstname        riya\n",
       "3  firstname       briza\n",
       "4  firstname  prosperity"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f955cafc-f5c6-4795-8f16-4332638a9402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0], dtype='int64')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "315fe4d8-3072-4cac-8ee1-52396deca8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/envs/llm/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: seqeval[gpu] in /opt/conda/envs/llm/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/llm/lib/python3.11/site-packages (from seqeval[gpu]) (1.5.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/llm/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c378da9f-12ca-4596-8e53-315bac6735a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/envs/llm/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/llm/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/llm/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/llm/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/llm/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b83d53e-5234-441d-9327-510e46824dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f660033-ab95-46d5-9495-5a23ace1c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.45.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfc8cc18-1a7f-46ee-864b-7f9d156f0658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fa61a49-bff1-4ce3-8fac-66766374817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies=melted_data['Entity'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3b91973-913e-4e8c-9053-f7a3eed2a608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['firstname', 'gender', 'lastname', 'zipcode', 'city', 'state'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f9a9a1bf-427e-4b75-a9b1-3794b2b89dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstname': 0,\n",
       " 'gender': 1,\n",
       " 'lastname': 2,\n",
       " 'zipcode': 3,\n",
       " 'city': 4,\n",
       " 'state': 5}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(frequencies)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(frequencies)}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "945bf688-5ae1-48c0-8be7-8d29c923c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.Value[index].strip().split()  \n",
    "        word_labels = [self.data.Entity[index]]\n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_split_into_words=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75859db5-f83a-486a-b21b-fd18858c2e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b3546ca21443a5bc4cbf5f5df5e596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5f656055bb4f2a8e9d9e57c162f6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec4d83e96214e96bbdc4bc24c96ff18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6c48a7d7af482ab7149a1725265d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VALID_BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79bd66f5-469e-4e0c-b12e-211d52189665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61ea27ce-a9e9-4173-bcce-058614994728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firstname</td>\n",
       "      <td>lanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firstname</td>\n",
       "      <td>ellanora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firstname</td>\n",
       "      <td>riya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firstname</td>\n",
       "      <td>briza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>firstname</td>\n",
       "      <td>prosperity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182755</th>\n",
       "      <td>state</td>\n",
       "      <td>wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182756</th>\n",
       "      <td>state</td>\n",
       "      <td>sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182757</th>\n",
       "      <td>state</td>\n",
       "      <td>ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182758</th>\n",
       "      <td>state</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182759</th>\n",
       "      <td>state</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Entity       Value\n",
       "0       firstname       lanya\n",
       "1       firstname    ellanora\n",
       "2       firstname        riya\n",
       "3       firstname       briza\n",
       "4       firstname  prosperity\n",
       "...           ...         ...\n",
       "182755      state          wv\n",
       "182756      state          sd\n",
       "182757      state          ny\n",
       "182758      state          co\n",
       "182759      state          fl\n",
       "\n",
       "[182760 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50c16b48-f746-4e93-abef-91a819807643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (182760, 2)\n",
      "TRAIN Dataset: (146208, 2)\n",
      "TEST Dataset: (36552, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = melted_data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = melted_data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(melted_data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7560adb-0131-4cb5-a0a3-c945b584cff5",
   "metadata": {},
   "source": [
    "//Dump : Pickle dump file\n",
    "// learning rate training accuracy  + validation accuracy : line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "85779f19-26b4-4a55-acc2-1f49089c1f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2128, 16368,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'offset_mapping': tensor([[0, 0],\n",
       "         [0, 2],\n",
       "         [2, 5],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]),\n",
       " 'labels': tensor([-100,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb9543ae-fb60-400e-915f-704214cc8e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstname': 0,\n",
       " 'gender': 1,\n",
       " 'lastname': 2,\n",
       " 'zipcode': 3,\n",
       " 'city': 4,\n",
       " 'state': 5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52f53a0f-1fee-45af-9377-d57520c31fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       -100\n",
      "re          2\n",
      "##hor       -100\n",
      "[SEP]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "  print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "415ba8b7-d736-41dc-a4ba-1cee797c1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5470af8-423c-4ccd-b5c2-9b84fb42c527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf45e4acccb6471a9488d0c58f5e159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuration = BertConfig(vocab_size=30_522)\n",
    "# model = BertForTokenClassification(config=configuration).from_pretrained('bert-base-cased', num_labels=len(labels_to_ids))\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids), id2label=ids_to_labels,label2id=labels_to_ids)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de431f53-314f-42d1-a876-fc49b5cbe137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0705, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "567aaca3-14e3-45af-b8d9-2cf9871b5eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb62765e-57b5-46ef-a177-e150c60436c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 6])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd0a55ea-39ac-4177-bee3-9bff32279667",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2875eff-492b-4a11-a4aa-c3e6dc38ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    print(\"training_loader*****\")\n",
    "    print(training_loader)\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    print(\" model.train()*****\")\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "        print(\" batch['labels']*****\")\n",
    "        print(labels)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee45d725-2db1-4a95-9aa8-09736bb9498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "233cfd12-dad1-4446-9dd2-7bc8ebb2f018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "training_loader*****\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa2b09b6690>\n",
      " model.train()*****\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[82], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model.train()*****\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[68], line 33\u001b[0m, in \u001b[0;36mdataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, mapping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m mapping[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mapping[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# overwrite label\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     encoded_labels[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# step 4: turn everything into PyTorch tensors\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8e38f-1758-4436-877b-704d9787e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9e0c8-e208-42cb-819e-bd925f01bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556848d-290d-42cc-812a-679d19c39d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
